{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "data = pd.concat([train, test]).drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>car</th>\n",
       "      <th>child_num</th>\n",
       "      <th>credit</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>email</th>\n",
       "      <th>family_size</th>\n",
       "      <th>family_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>house_type</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>phone</th>\n",
       "      <th>reality</th>\n",
       "      <th>work_phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>6.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>F</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>F</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>M</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Managers</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>37.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>F</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>F</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Managers</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAYS_BIRTH  DAYS_EMPLOYED  begin_month car  child_num  credit  \\\n",
       "0       13899           4709          6.0   N          0     1.0   \n",
       "1       11380           1540          5.0   N          1     1.0   \n",
       "2       19087           4434         22.0   Y          0     2.0   \n",
       "3       15088           2092         37.0   N          0     0.0   \n",
       "4       15037           2105         26.0   Y          0     2.0   \n",
       "\n",
       "                        edu_type  email  family_size     family_type gender  \\\n",
       "0               Higher education      0          2.0         Married      F   \n",
       "1  Secondary / secondary special      1          3.0  Civil marriage      F   \n",
       "2               Higher education      0          2.0         Married      M   \n",
       "3  Secondary / secondary special      0          2.0         Married      F   \n",
       "4               Higher education      0          2.0         Married      F   \n",
       "\n",
       "            house_type  income_total           income_type   occyp_type  \\\n",
       "0  Municipal apartment      202500.0  Commercial associate          NaN   \n",
       "1    House / apartment      247500.0  Commercial associate     Laborers   \n",
       "2    House / apartment      450000.0               Working     Managers   \n",
       "3    House / apartment      202500.0  Commercial associate  Sales staff   \n",
       "4    House / apartment      157500.0         State servant     Managers   \n",
       "\n",
       "   phone reality  work_phone  \n",
       "0      0       N           0  \n",
       "1      0       Y           0  \n",
       "2      1       Y           0  \n",
       "3      1       Y           0  \n",
       "4      0       Y           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 사람은 핸드폰을 가지고 있다.\n",
    "data = data.drop(['FLAG_MOBIL'], axis=1)\n",
    "\n",
    "# 음수들 양수로 변환 변환\n",
    "data['DAYS_BIRTH'] = -data['DAYS_BIRTH']\n",
    "data['DAYS_EMPLOYED'] = -data['DAYS_EMPLOYED']\n",
    "data['begin_month'] = -data['begin_month']\n",
    "\n",
    "# DAYS_EMPLOYED : 일하고 있지 않은 사람들 0으로\n",
    "data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].apply(lambda x : x if x >=0 else 0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋\n",
    "### 이산형 자료형\n",
    "1. gender(성별)\n",
    "2. car(차 소유 유무)\n",
    "3. reality(부동산 소유 우무)\n",
    "4. income_type(소득 분류) \n",
    "    - Commercial associate : 상업 관계자..? \n",
    "    - Pensioner : 연금 수령자 \n",
    "5. edu_type(교육 수준)\n",
    "6. familly_type(결혼 여부)\n",
    "7. house_type(생활 방식)\n",
    "8. FLAG_MOBIL(핸드폰 소유 여부)\n",
    "9. work_phone(업무용 전화 소유 여부)\n",
    "10. phone(전화 소유 여부)\n",
    "11. email(이메일 소유 여부)\n",
    "12. occyp_type(직업 유형)\n",
    "\n",
    "### 연속형\n",
    "1. child_num(자녀 수)\n",
    "2. income_total(연간 소득)\n",
    "3. DAYS_BIRTH(출생일)\n",
    "4. DAYS_EMPLOYED(업무 시작일)\n",
    "5. family_size(가족 규모)\n",
    "6. begin_month(신용카드 발급 월)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Log-transformation of the target variable\n",
    "- 이상치를 모두 제거하는 대신에 후에 모델에서 이런 데이터를 제어하는 방법을 배울 것입니다.\n",
    "- RL이 최빈값으로 빈 부분은 RL로 채웁니다. mode 메서드는 가장 많이 나타나는 값을 자동으로 선택해줍니다.\n",
    "- occyp_type : 결측이 존재 : 결측에 수입이 있는걸로 봐서 아에 no_job은 아닌듯! -> 클러스터링 등의 방법으로 결측을 채워보자! work_phone, phone, email, car, reality, edu_type, income_total 등으로 채워보자 !\n",
    "- Box-Cox Transformation은 정규 분포가 아닌 데이터를 정규 분포 형태로 변환하는 방법 중 하나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36457, 19)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "data = pd.concat([train, test]).drop(['index'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36457, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>car</th>\n",
       "      <th>credit</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>email</th>\n",
       "      <th>family_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>house_type</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>phone</th>\n",
       "      <th>reality</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>adult</th>\n",
       "      <th>adult_family_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAYS_BIRTH  DAYS_EMPLOYED  begin_month  car  credit  edu_type  email  \\\n",
       "0       13899           4709          6.0    0     1.0         3      0   \n",
       "1       11380           1540          5.0    0     1.0         1      1   \n",
       "2       19087           4434         22.0    1     2.0         3      0   \n",
       "3       15088           2092         37.0    0     0.0         1      0   \n",
       "4       15037           2105         26.0    1     2.0         3      0   \n",
       "\n",
       "   family_type  gender  house_type  income_total  income_type  occyp_type  \\\n",
       "0            1       0           2      202500.0            0          12   \n",
       "1            0       0           1      247500.0            0           8   \n",
       "2            1       1           1      450000.0            4          10   \n",
       "3            1       0           1      202500.0            0          15   \n",
       "4            1       0           1      157500.0            2          10   \n",
       "\n",
       "   phone  reality  work_phone  adult  adult_family_ratio  \n",
       "0      0        0           0    2.0                 1.0  \n",
       "1      0        1           0    2.0                 1.5  \n",
       "2      1        1           0    2.0                 1.0  \n",
       "3      1        1           0    2.0                 1.0  \n",
       "4      0        1           0    2.0                 1.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 사람은 핸드폰을 가지고 있다.\n",
    "data = data.drop(['FLAG_MOBIL'], axis=1)\n",
    "\n",
    "# 음수들 양수로 변환 변환\n",
    "data['DAYS_BIRTH'] = -data['DAYS_BIRTH']\n",
    "data['DAYS_EMPLOYED'] = -data['DAYS_EMPLOYED']\n",
    "data['begin_month'] = -data['begin_month']\n",
    "\n",
    "# DAYS_EMPLOYED : 일하고 있지 않은 사람들 0으로\n",
    "data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].apply(lambda x : x if x >=0 else 0)\n",
    "\n",
    "# 무직자들(DAYS_EMPLOYED < 0)은 모두 occyp_type이 NaN이다! -> noJob\n",
    "occyp_type = []\n",
    "for i, x in data.iterrows():\n",
    "    if x.DAYS_EMPLOYED < 0:\n",
    "        occyp_type.append('noJob')\n",
    "    else:\n",
    "        occyp_type.append(x.occyp_type)\n",
    "data['occyp_type'] = occyp_type\n",
    "\n",
    "# 남은 NaN값들을 채워주자! -> 클러스터링\n",
    "\n",
    "\n",
    "# 어른 1명당 부양가족\n",
    "data['adult'] = data['family_size'] - data['child_num']\n",
    "adult_family_ratio = []\n",
    "for i, x in data.iterrows():\n",
    "    if x.adult > 0:\n",
    "        adult_family_ratio.append(x.family_size / x.adult)\n",
    "    else:\n",
    "        adult_family_ratio.append(5)\n",
    "data['adult_family_ratio'] = adult_family_ratio\n",
    "data['adult_family_ratio'] = data['adult_family_ratio'].apply(lambda x: x if x<=4 else 5)\n",
    "\n",
    "data = data.drop(['family_size', 'child_num'], axis = 1)\n",
    "\n",
    "# edu_type 순서화\n",
    "edu_dict = {'Secondary / secondary special' : 2, 'Higher education' : 4,'Incomplete higher' : 3, 'Lower secondary' : 1, 'Academic degree' : 5}\n",
    "data['edu_type'] = data['edu_type'].apply(lambda x: edu_dict[x])\n",
    "\n",
    "# 연속형 변수 스케일링\n",
    "# income_total : robust scaling\n",
    "# DAYS_BIRTH, begin_month : standard scaling\n",
    "#rbScaler = RobustScaler()\n",
    "#data['income_total'] = rbScaler.fit_transform(data[['income_total']])\n",
    "#sdScaler = StandardScaler()\n",
    "#data[['DAYS_BIRTH', 'begin_month']] = sdScaler.fit_transform(data[['DAYS_BIRTH', 'begin_month']])\n",
    "\n",
    "# 범주형 변수 인코딩\n",
    "category_list = ['car', 'email', 'gender', 'phone','reality', 'work_phone',\n",
    "                 'edu_type', 'family_type', 'house_type', 'income_type', 'occyp_type']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for cat in category_list:\n",
    "    lbl = LabelEncoder()\n",
    "    if cat == 'occyp_type':\n",
    "        pass\n",
    "        data['occyp_type'] = data['occyp_type'].fillna('NaN')\n",
    "        data['occyp_type'] = lbl.fit_transform(data['occyp_type'].values)\n",
    "        #data['occyp_type'] = data['occyp_type'].replace(12, np.NaN)\n",
    "    else:\n",
    "        data[cat] = lbl.fit_transform(data[cat].values)\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = data['credit']\n",
    "del data['credit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://datawig.readthedocs.io/en/latest/index.html\n",
    "import datawig\n",
    "\n",
    "cols = list(data.columns)\n",
    "cols.remove('occyp_type')\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns= cols, # column(s) containing information about the column we want to impute\n",
    "    output_column='occyp_type', # the column we'd like to impute values for\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=data, num_epochs=50)\n",
    "\n",
    "#Impute missing values and return original dataframe with predictions\n",
    "imputed = imputer.predict(data)\n",
    "imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56610994e+04, -2.04283492e+03, -2.42620490e+03,\n",
       "         1.99638687e+01,  2.87304942e+00],\n",
       "       [ 6.02194862e+04, -4.37454263e+03,  8.29872775e+02,\n",
       "         2.09529295e+01, -1.06579165e+00],\n",
       "       [ 2.60702649e+05,  3.77513226e+03, -1.75188899e+03,\n",
       "         4.12121369e+00,  7.45828312e-01],\n",
       "       ...,\n",
       "       [ 1.04759175e+05,  5.13580671e+03, -1.15649500e+04,\n",
       "        -2.85502161e+01,  1.80339250e+00],\n",
       "       [-6.62049089e+03,  5.55515523e+02,  1.08401259e+03,\n",
       "        -6.76920174e+00,  2.87045949e+00],\n",
       "       [ 8.25002235e+04, -6.50008713e+03,  2.24146061e+03,\n",
       "         1.50128866e+01, -1.20369232e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, SparsePCA \n",
    "pca = SparsePCA(n_components = 5)\n",
    "data = pca.fit_transform(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "imputed['occyp_type'] = lbl.fit_transform(imputed['occyp_type_imputed'])\n",
    "data = imputed.drop(['occyp_type_imputed', 'occyp_type_imputed_proba'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26457, 17)\n",
      "(10000, 17)\n",
      "(26457,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data[credit.notnull()]\n",
    "X_test = data[credit.isnull()]\n",
    "y_train = credit.dropna().astype(int)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스태킹\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,  GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = train_test_split(X_train, y_train, test_size=0.3, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BAYESIAN_PARAMETER_OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter 별로 search할 범위를 설정. \n",
    "bayesian_params = {\n",
    "    'max_depth': (1, 5), \n",
    "    'num_leaves': (24, 64), \n",
    "    'min_child_samples': (10, 200), \n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha': (0.001, 10) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        \"n_estimators\":500, \"learning_rate\":0.02,\n",
    "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
    "        'num_leaves': int(round(num_leaves)), \n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample': max(min(subsample, 1), 0), \n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'max_bin':  max(int(round(max_bin)),10),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_proba = lgb_model.predict_proba(valid_x)\n",
    "    logLoss = log_loss(valid_y, valid_proba)\n",
    "    \n",
    "    return -logLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.808849\tvalid_1's multi_logloss: 0.816704\n",
      "[200]\ttraining's multi_logloss: 0.797531\tvalid_1's multi_logloss: 0.808195\n",
      "[300]\ttraining's multi_logloss: 0.791058\tvalid_1's multi_logloss: 0.804895\n",
      "[400]\ttraining's multi_logloss: 0.786271\tvalid_1's multi_logloss: 0.802554\n",
      "[500]\ttraining's multi_logloss: 0.782319\tvalid_1's multi_logloss: 0.800966\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.782319\tvalid_1's multi_logloss: 0.800966\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.801   \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 360.4   \u001b[0m | \u001b[0m 3.411   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 49.84   \u001b[0m | \u001b[0m 4.376   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.807847\tvalid_1's multi_logloss: 0.816469\n",
      "[200]\ttraining's multi_logloss: 0.795932\tvalid_1's multi_logloss: 0.807691\n",
      "[300]\ttraining's multi_logloss: 0.789306\tvalid_1's multi_logloss: 0.804129\n",
      "[400]\ttraining's multi_logloss: 0.784523\tvalid_1's multi_logloss: 0.802262\n",
      "[500]\ttraining's multi_logloss: 0.779524\tvalid_1's multi_logloss: 0.800378\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.779524\tvalid_1's multi_logloss: 0.800378\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.8004  \u001b[0m | \u001b[95m 0.6917  \u001b[0m | \u001b[95m 397.9   \u001b[0m | \u001b[95m 3.116   \u001b[0m | \u001b[95m 117.9   \u001b[0m | \u001b[95m 46.35   \u001b[0m | \u001b[95m 26.84   \u001b[0m | \u001b[95m 0.8722  \u001b[0m | \u001b[95m 0.2032  \u001b[0m | \u001b[95m 0.9163  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.794874\tvalid_1's multi_logloss: 0.809679\n",
      "[200]\ttraining's multi_logloss: 0.776861\tvalid_1's multi_logloss: 0.800568\n",
      "[300]\ttraining's multi_logloss: 0.765138\tvalid_1's multi_logloss: 0.796094\n",
      "[400]\ttraining's multi_logloss: 0.754945\tvalid_1's multi_logloss: 0.793035\n",
      "[500]\ttraining's multi_logloss: 0.746102\tvalid_1's multi_logloss: 0.790466\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.746102\tvalid_1's multi_logloss: 0.790466\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.7905  \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 436.3   \u001b[0m | \u001b[95m 4.914   \u001b[0m | \u001b[95m 161.8   \u001b[0m | \u001b[95m 23.61   \u001b[0m | \u001b[95m 55.22   \u001b[0m | \u001b[95m 1.184   \u001b[0m | \u001b[95m 6.4     \u001b[0m | \u001b[95m 0.5717  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.806433\tvalid_1's multi_logloss: 0.81385\n",
      "[200]\ttraining's multi_logloss: 0.796564\tvalid_1's multi_logloss: 0.807489\n",
      "[300]\ttraining's multi_logloss: 0.790965\tvalid_1's multi_logloss: 0.805023\n",
      "[400]\ttraining's multi_logloss: 0.785881\tvalid_1's multi_logloss: 0.802742\n",
      "[500]\ttraining's multi_logloss: 0.781334\tvalid_1's multi_logloss: 0.800969\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.781334\tvalid_1's multi_logloss: 0.800969\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.801   \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 265.7   \u001b[0m | \u001b[0m 2.659   \u001b[0m | \u001b[0m 60.27   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 42.25   \u001b[0m | \u001b[0m 5.685   \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.8088  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.797538\tvalid_1's multi_logloss: 0.811403\n",
      "[200]\ttraining's multi_logloss: 0.779829\tvalid_1's multi_logloss: 0.801738\n",
      "[300]\ttraining's multi_logloss: 0.767858\tvalid_1's multi_logloss: 0.797762\n",
      "[400]\ttraining's multi_logloss: 0.75855\tvalid_1's multi_logloss: 0.794279\n",
      "[500]\ttraining's multi_logloss: 0.74998\tvalid_1's multi_logloss: 0.791834\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.74998\tvalid_1's multi_logloss: 0.791834\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.7918  \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 312.3   \u001b[0m | \u001b[0m 4.775   \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 41.48   \u001b[0m | \u001b[0m 6.977   \u001b[0m | \u001b[0m 0.6032  \u001b[0m | \u001b[0m 0.8334  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.81244\tvalid_1's multi_logloss: 0.822611\n",
      "[200]\ttraining's multi_logloss: 0.802902\tvalid_1's multi_logloss: 0.818056\n",
      "[300]\ttraining's multi_logloss: 0.796323\tvalid_1's multi_logloss: 0.815827\n",
      "[400]\ttraining's multi_logloss: 0.791047\tvalid_1's multi_logloss: 0.814387\n",
      "[500]\ttraining's multi_logloss: 0.786216\tvalid_1's multi_logloss: 0.813193\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.786216\tvalid_1's multi_logloss: 0.813193\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.8132  \u001b[0m | \u001b[0m 0.8685  \u001b[0m | \u001b[0m 15.08   \u001b[0m | \u001b[0m 4.814   \u001b[0m | \u001b[0m 198.4   \u001b[0m | \u001b[0m 45.77   \u001b[0m | \u001b[0m 60.79   \u001b[0m | \u001b[0m 9.691   \u001b[0m | \u001b[0m 7.013   \u001b[0m | \u001b[0m 0.6276  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.825655\tvalid_1's multi_logloss: 0.830963\n",
      "[200]\ttraining's multi_logloss: 0.819487\tvalid_1's multi_logloss: 0.82504\n",
      "[300]\ttraining's multi_logloss: 0.817921\tvalid_1's multi_logloss: 0.823914\n",
      "[400]\ttraining's multi_logloss: 0.817036\tvalid_1's multi_logloss: 0.823349\n",
      "[500]\ttraining's multi_logloss: 0.816483\tvalid_1's multi_logloss: 0.823076\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.816483\tvalid_1's multi_logloss: 0.823076\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.8231  \u001b[0m | \u001b[0m 0.5589  \u001b[0m | \u001b[0m 15.7    \u001b[0m | \u001b[0m 1.49    \u001b[0m | \u001b[0m 18.73   \u001b[0m | \u001b[0m 1.035   \u001b[0m | \u001b[0m 34.83   \u001b[0m | \u001b[0m 8.617   \u001b[0m | \u001b[0m 3.653   \u001b[0m | \u001b[0m 0.8043  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.805498\tvalid_1's multi_logloss: 0.816869\n",
      "[200]\ttraining's multi_logloss: 0.789234\tvalid_1's multi_logloss: 0.806031\n",
      "[300]\ttraining's multi_logloss: 0.780785\tvalid_1's multi_logloss: 0.802288\n",
      "[400]\ttraining's multi_logloss: 0.774041\tvalid_1's multi_logloss: 0.79999\n",
      "[500]\ttraining's multi_logloss: 0.768432\tvalid_1's multi_logloss: 0.798555\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.768432\tvalid_1's multi_logloss: 0.798555\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.7986  \u001b[0m | \u001b[0m 0.607   \u001b[0m | \u001b[0m 320.2   \u001b[0m | \u001b[0m 4.06    \u001b[0m | \u001b[0m 192.7   \u001b[0m | \u001b[0m 46.79   \u001b[0m | \u001b[0m 62.76   \u001b[0m | \u001b[0m 0.09772 \u001b[0m | \u001b[0m 1.72    \u001b[0m | \u001b[0m 0.9426  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.79984\tvalid_1's multi_logloss: 0.812822\n",
      "[200]\ttraining's multi_logloss: 0.782025\tvalid_1's multi_logloss: 0.80252\n",
      "[300]\ttraining's multi_logloss: 0.769975\tvalid_1's multi_logloss: 0.797382\n",
      "[400]\ttraining's multi_logloss: 0.759919\tvalid_1's multi_logloss: 0.793077\n",
      "[500]\ttraining's multi_logloss: 0.750654\tvalid_1's multi_logloss: 0.789392\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.750654\tvalid_1's multi_logloss: 0.789392\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.7894  \u001b[0m | \u001b[95m 0.7415  \u001b[0m | \u001b[95m 489.9   \u001b[0m | \u001b[95m 3.645   \u001b[0m | \u001b[95m 13.89   \u001b[0m | \u001b[95m 1.719   \u001b[0m | \u001b[95m 47.39   \u001b[0m | \u001b[95m 2.662   \u001b[0m | \u001b[95m 0.646   \u001b[0m | \u001b[95m 0.7276  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.807835\tvalid_1's multi_logloss: 0.81575\n",
      "[200]\ttraining's multi_logloss: 0.796697\tvalid_1's multi_logloss: 0.807843\n",
      "[300]\ttraining's multi_logloss: 0.790154\tvalid_1's multi_logloss: 0.80465\n",
      "[400]\ttraining's multi_logloss: 0.785352\tvalid_1's multi_logloss: 0.8023\n",
      "[500]\ttraining's multi_logloss: 0.78089\tvalid_1's multi_logloss: 0.80038\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.78089\tvalid_1's multi_logloss: 0.80038\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.8004  \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 481.8   \u001b[0m | \u001b[0m 2.686   \u001b[0m | \u001b[0m 21.2    \u001b[0m | \u001b[0m 26.07   \u001b[0m | \u001b[0m 45.01   \u001b[0m | \u001b[0m 2.965   \u001b[0m | \u001b[0m 9.784   \u001b[0m | \u001b[0m 0.9078  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.814584\tvalid_1's multi_logloss: 0.819118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's multi_logloss: 0.807813\tvalid_1's multi_logloss: 0.812552\n",
      "[300]\ttraining's multi_logloss: 0.805655\tvalid_1's multi_logloss: 0.810808\n",
      "[400]\ttraining's multi_logloss: 0.804594\tvalid_1's multi_logloss: 0.810325\n",
      "[500]\ttraining's multi_logloss: 0.80391\tvalid_1's multi_logloss: 0.809945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.80391\tvalid_1's multi_logloss: 0.809945\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.8099  \u001b[0m | \u001b[0m 0.8876  \u001b[0m | \u001b[0m 478.8   \u001b[0m | \u001b[0m 1.239   \u001b[0m | \u001b[0m 196.2   \u001b[0m | \u001b[0m 1.81    \u001b[0m | \u001b[0m 31.77   \u001b[0m | \u001b[0m 9.662   \u001b[0m | \u001b[0m 8.428   \u001b[0m | \u001b[0m 0.9965  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.811025\tvalid_1's multi_logloss: 0.819099\n",
      "[200]\ttraining's multi_logloss: 0.797855\tvalid_1's multi_logloss: 0.808455\n",
      "[300]\ttraining's multi_logloss: 0.791509\tvalid_1's multi_logloss: 0.80513\n",
      "[400]\ttraining's multi_logloss: 0.786705\tvalid_1's multi_logloss: 0.802922\n",
      "[500]\ttraining's multi_logloss: 0.782817\tvalid_1's multi_logloss: 0.801388\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.782817\tvalid_1's multi_logloss: 0.801388\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.8014  \u001b[0m | \u001b[0m 0.5822  \u001b[0m | \u001b[0m 431.9   \u001b[0m | \u001b[0m 3.496   \u001b[0m | \u001b[0m 165.2   \u001b[0m | \u001b[0m 15.98   \u001b[0m | \u001b[0m 56.12   \u001b[0m | \u001b[0m 4.05    \u001b[0m | \u001b[0m 4.854   \u001b[0m | \u001b[0m 0.6698  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.80148\tvalid_1's multi_logloss: 0.815771\n",
      "[200]\ttraining's multi_logloss: 0.782122\tvalid_1's multi_logloss: 0.803316\n",
      "[300]\ttraining's multi_logloss: 0.771423\tvalid_1's multi_logloss: 0.799005\n",
      "[400]\ttraining's multi_logloss: 0.762132\tvalid_1's multi_logloss: 0.796491\n",
      "[500]\ttraining's multi_logloss: 0.753881\tvalid_1's multi_logloss: 0.794498\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.753881\tvalid_1's multi_logloss: 0.794498\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.7945  \u001b[0m | \u001b[0m 0.5175  \u001b[0m | \u001b[0m 122.8   \u001b[0m | \u001b[0m 4.502   \u001b[0m | \u001b[0m 182.9   \u001b[0m | \u001b[0m 4.801   \u001b[0m | \u001b[0m 24.5    \u001b[0m | \u001b[0m 0.3937  \u001b[0m | \u001b[0m 6.267   \u001b[0m | \u001b[0m 0.5975  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.807901\tvalid_1's multi_logloss: 0.816193\n",
      "[200]\ttraining's multi_logloss: 0.796174\tvalid_1's multi_logloss: 0.807618\n",
      "[300]\ttraining's multi_logloss: 0.789597\tvalid_1's multi_logloss: 0.804389\n",
      "[400]\ttraining's multi_logloss: 0.784955\tvalid_1's multi_logloss: 0.802573\n",
      "[500]\ttraining's multi_logloss: 0.780582\tvalid_1's multi_logloss: 0.800787\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.780582\tvalid_1's multi_logloss: 0.800787\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.8008  \u001b[0m | \u001b[0m 0.77    \u001b[0m | \u001b[0m 156.9   \u001b[0m | \u001b[0m 2.517   \u001b[0m | \u001b[0m 111.2   \u001b[0m | \u001b[0m 1.892   \u001b[0m | \u001b[0m 63.82   \u001b[0m | \u001b[0m 1.628   \u001b[0m | \u001b[0m 5.643   \u001b[0m | \u001b[0m 0.7808  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.796917\tvalid_1's multi_logloss: 0.811617\n",
      "[200]\ttraining's multi_logloss: 0.779738\tvalid_1's multi_logloss: 0.802578\n",
      "[300]\ttraining's multi_logloss: 0.769878\tvalid_1's multi_logloss: 0.798725\n",
      "[400]\ttraining's multi_logloss: 0.761213\tvalid_1's multi_logloss: 0.796579\n",
      "[500]\ttraining's multi_logloss: 0.753501\tvalid_1's multi_logloss: 0.794877\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.753501\tvalid_1's multi_logloss: 0.794877\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.7949  \u001b[0m | \u001b[0m 0.8353  \u001b[0m | \u001b[0m 107.8   \u001b[0m | \u001b[0m 4.884   \u001b[0m | \u001b[0m 97.0    \u001b[0m | \u001b[0m 45.17   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 0.8944  \u001b[0m | \u001b[0m 5.507   \u001b[0m | \u001b[0m 0.5417  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.796592\tvalid_1's multi_logloss: 0.810059\n",
      "[200]\ttraining's multi_logloss: 0.780189\tvalid_1's multi_logloss: 0.80199\n",
      "[300]\ttraining's multi_logloss: 0.769309\tvalid_1's multi_logloss: 0.797558\n",
      "[400]\ttraining's multi_logloss: 0.760077\tvalid_1's multi_logloss: 0.795356\n",
      "[500]\ttraining's multi_logloss: 0.752498\tvalid_1's multi_logloss: 0.793309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.752498\tvalid_1's multi_logloss: 0.793309\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.7933  \u001b[0m | \u001b[0m 0.9688  \u001b[0m | \u001b[0m 491.8   \u001b[0m | \u001b[0m 4.509   \u001b[0m | \u001b[0m 126.1   \u001b[0m | \u001b[0m 49.56   \u001b[0m | \u001b[0m 63.74   \u001b[0m | \u001b[0m 1.871   \u001b[0m | \u001b[0m 6.551   \u001b[0m | \u001b[0m 0.9542  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.806288\tvalid_1's multi_logloss: 0.815409\n",
      "[200]\ttraining's multi_logloss: 0.793831\tvalid_1's multi_logloss: 0.806745\n",
      "[300]\ttraining's multi_logloss: 0.786531\tvalid_1's multi_logloss: 0.803339\n",
      "[400]\ttraining's multi_logloss: 0.780911\tvalid_1's multi_logloss: 0.801025\n",
      "[500]\ttraining's multi_logloss: 0.776004\tvalid_1's multi_logloss: 0.798911\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.776004\tvalid_1's multi_logloss: 0.798911\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.7989  \u001b[0m | \u001b[0m 0.8435  \u001b[0m | \u001b[0m 249.3   \u001b[0m | \u001b[0m 2.867   \u001b[0m | \u001b[0m 12.66   \u001b[0m | \u001b[0m 6.27    \u001b[0m | \u001b[0m 24.88   \u001b[0m | \u001b[0m 0.6401  \u001b[0m | \u001b[0m 3.806   \u001b[0m | \u001b[0m 0.9283  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.802783\tvalid_1's multi_logloss: 0.815114\n",
      "[200]\ttraining's multi_logloss: 0.786143\tvalid_1's multi_logloss: 0.803906\n",
      "[300]\ttraining's multi_logloss: 0.776101\tvalid_1's multi_logloss: 0.799729\n",
      "[400]\ttraining's multi_logloss: 0.768612\tvalid_1's multi_logloss: 0.796438\n",
      "[500]\ttraining's multi_logloss: 0.76115\tvalid_1's multi_logloss: 0.793707\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.76115\tvalid_1's multi_logloss: 0.793707\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.7937  \u001b[0m | \u001b[0m 0.6207  \u001b[0m | \u001b[0m 499.6   \u001b[0m | \u001b[0m 4.253   \u001b[0m | \u001b[0m 85.33   \u001b[0m | \u001b[0m 7.194   \u001b[0m | \u001b[0m 28.07   \u001b[0m | \u001b[0m 0.7263  \u001b[0m | \u001b[0m 6.594   \u001b[0m | \u001b[0m 0.6209  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.794878\tvalid_1's multi_logloss: 0.811068\n",
      "[200]\ttraining's multi_logloss: 0.775115\tvalid_1's multi_logloss: 0.800612\n",
      "[300]\ttraining's multi_logloss: 0.761899\tvalid_1's multi_logloss: 0.7961\n",
      "[400]\ttraining's multi_logloss: 0.750394\tvalid_1's multi_logloss: 0.792767\n",
      "[500]\ttraining's multi_logloss: 0.739699\tvalid_1's multi_logloss: 0.789668\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.739699\tvalid_1's multi_logloss: 0.789668\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.7897  \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 228.7   \u001b[0m | \u001b[0m 4.912   \u001b[0m | \u001b[0m 143.3   \u001b[0m | \u001b[0m 1.532   \u001b[0m | \u001b[0m 27.24   \u001b[0m | \u001b[0m 0.9822  \u001b[0m | \u001b[0m 0.2924  \u001b[0m | \u001b[0m 0.9468  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.789332\tvalid_1's multi_logloss: 0.808525\n",
      "[200]\ttraining's multi_logloss: 0.768196\tvalid_1's multi_logloss: 0.798688\n",
      "[300]\ttraining's multi_logloss: 0.753123\tvalid_1's multi_logloss: 0.792867\n",
      "[400]\ttraining's multi_logloss: 0.739681\tvalid_1's multi_logloss: 0.788587\n",
      "[500]\ttraining's multi_logloss: 0.725648\tvalid_1's multi_logloss: 0.78518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.725648\tvalid_1's multi_logloss: 0.78518\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-0.7852  \u001b[0m | \u001b[95m 0.9952  \u001b[0m | \u001b[95m 223.7   \u001b[0m | \u001b[95m 4.79    \u001b[0m | \u001b[95m 13.07   \u001b[0m | \u001b[95m 11.12   \u001b[0m | \u001b[95m 59.92   \u001b[0m | \u001b[95m 1.23    \u001b[0m | \u001b[95m 1.109   \u001b[0m | \u001b[95m 0.5765  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.794694\tvalid_1's multi_logloss: 0.812128\n",
      "[200]\ttraining's multi_logloss: 0.773507\tvalid_1's multi_logloss: 0.799591\n",
      "[300]\ttraining's multi_logloss: 0.760313\tvalid_1's multi_logloss: 0.794985\n",
      "[400]\ttraining's multi_logloss: 0.750508\tvalid_1's multi_logloss: 0.791251\n",
      "[500]\ttraining's multi_logloss: 0.740723\tvalid_1's multi_logloss: 0.788094\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.740723\tvalid_1's multi_logloss: 0.788094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.7881  \u001b[0m | \u001b[0m 0.646   \u001b[0m | \u001b[0m 390.3   \u001b[0m | \u001b[0m 4.547   \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 21.04   \u001b[0m | \u001b[0m 62.31   \u001b[0m | \u001b[0m 0.6139  \u001b[0m | \u001b[0m 3.969   \u001b[0m | \u001b[0m 0.8906  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.790084\tvalid_1's multi_logloss: 0.808096\n",
      "[200]\ttraining's multi_logloss: 0.766995\tvalid_1's multi_logloss: 0.79817\n",
      "[300]\ttraining's multi_logloss: 0.750884\tvalid_1's multi_logloss: 0.792347\n",
      "[400]\ttraining's multi_logloss: 0.736182\tvalid_1's multi_logloss: 0.787318\n",
      "[500]\ttraining's multi_logloss: 0.723057\tvalid_1's multi_logloss: 0.783736\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.723057\tvalid_1's multi_logloss: 0.783736\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m-0.7837  \u001b[0m | \u001b[95m 0.9648  \u001b[0m | \u001b[95m 491.6   \u001b[0m | \u001b[95m 4.885   \u001b[0m | \u001b[95m 41.0    \u001b[0m | \u001b[95m 2.127   \u001b[0m | \u001b[95m 57.85   \u001b[0m | \u001b[95m 2.011   \u001b[0m | \u001b[95m 1.687   \u001b[0m | \u001b[95m 0.9764  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.803257\tvalid_1's multi_logloss: 0.812695\n",
      "[200]\ttraining's multi_logloss: 0.791614\tvalid_1's multi_logloss: 0.806268\n",
      "[300]\ttraining's multi_logloss: 0.784459\tvalid_1's multi_logloss: 0.803224\n",
      "[400]\ttraining's multi_logloss: 0.7789\tvalid_1's multi_logloss: 0.801011\n",
      "[500]\ttraining's multi_logloss: 0.77328\tvalid_1's multi_logloss: 0.799383\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.77328\tvalid_1's multi_logloss: 0.799383\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.7994  \u001b[0m | \u001b[0m 0.9707  \u001b[0m | \u001b[0m 151.7   \u001b[0m | \u001b[0m 3.951   \u001b[0m | \u001b[0m 46.18   \u001b[0m | \u001b[0m 37.89   \u001b[0m | \u001b[0m 38.31   \u001b[0m | \u001b[0m 9.579   \u001b[0m | \u001b[0m 5.181   \u001b[0m | \u001b[0m 0.5227  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.800961\tvalid_1's multi_logloss: 0.814889\n",
      "[200]\ttraining's multi_logloss: 0.781225\tvalid_1's multi_logloss: 0.801743\n",
      "[300]\ttraining's multi_logloss: 0.77047\tvalid_1's multi_logloss: 0.797089\n",
      "[400]\ttraining's multi_logloss: 0.762235\tvalid_1's multi_logloss: 0.794572\n",
      "[500]\ttraining's multi_logloss: 0.754867\tvalid_1's multi_logloss: 0.792422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.754867\tvalid_1's multi_logloss: 0.792422\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.7924  \u001b[0m | \u001b[0m 0.5397  \u001b[0m | \u001b[0m 496.8   \u001b[0m | \u001b[0m 4.602   \u001b[0m | \u001b[0m 10.63   \u001b[0m | \u001b[0m 39.87   \u001b[0m | \u001b[0m 62.17   \u001b[0m | \u001b[0m 3.261   \u001b[0m | \u001b[0m 2.437   \u001b[0m | \u001b[0m 0.9837  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.798089\tvalid_1's multi_logloss: 0.811614\n",
      "[200]\ttraining's multi_logloss: 0.779712\tvalid_1's multi_logloss: 0.801024\n",
      "[300]\ttraining's multi_logloss: 0.766955\tvalid_1's multi_logloss: 0.796475\n",
      "[400]\ttraining's multi_logloss: 0.757171\tvalid_1's multi_logloss: 0.792613\n",
      "[500]\ttraining's multi_logloss: 0.7483\tvalid_1's multi_logloss: 0.789625\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.7483\tvalid_1's multi_logloss: 0.789625\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.7896  \u001b[0m | \u001b[0m 0.8184  \u001b[0m | \u001b[0m 495.8   \u001b[0m | \u001b[0m 4.893   \u001b[0m | \u001b[0m 43.15   \u001b[0m | \u001b[0m 2.613   \u001b[0m | \u001b[0m 57.12   \u001b[0m | \u001b[0m 8.236   \u001b[0m | \u001b[0m 6.945   \u001b[0m | \u001b[0m 0.6594  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.793552\tvalid_1's multi_logloss: 0.812818\n",
      "[200]\ttraining's multi_logloss: 0.768108\tvalid_1's multi_logloss: 0.798007\n",
      "[300]\ttraining's multi_logloss: 0.751947\tvalid_1's multi_logloss: 0.791658\n",
      "[400]\ttraining's multi_logloss: 0.740059\tvalid_1's multi_logloss: 0.788208\n",
      "[500]\ttraining's multi_logloss: 0.729101\tvalid_1's multi_logloss: 0.784926\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.729101\tvalid_1's multi_logloss: 0.784926\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.7849  \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 300.7   \u001b[0m | \u001b[0m 4.954   \u001b[0m | \u001b[0m 42.65   \u001b[0m | \u001b[0m 7.485   \u001b[0m | \u001b[0m 59.56   \u001b[0m | \u001b[0m 0.7778  \u001b[0m | \u001b[0m 0.7676  \u001b[0m | \u001b[0m 0.9923  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.800786\tvalid_1's multi_logloss: 0.813542\n",
      "[200]\ttraining's multi_logloss: 0.784168\tvalid_1's multi_logloss: 0.803135\n",
      "[300]\ttraining's multi_logloss: 0.77478\tvalid_1's multi_logloss: 0.799535\n",
      "[400]\ttraining's multi_logloss: 0.767384\tvalid_1's multi_logloss: 0.797199\n",
      "[500]\ttraining's multi_logloss: 0.761079\tvalid_1's multi_logloss: 0.795596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.761079\tvalid_1's multi_logloss: 0.795596\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.7956  \u001b[0m | \u001b[0m 0.7213  \u001b[0m | \u001b[0m 151.3   \u001b[0m | \u001b[0m 4.911   \u001b[0m | \u001b[0m 192.5   \u001b[0m | \u001b[0m 47.75   \u001b[0m | \u001b[0m 26.41   \u001b[0m | \u001b[0m 5.275   \u001b[0m | \u001b[0m 6.619   \u001b[0m | \u001b[0m 0.5833  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.790037\tvalid_1's multi_logloss: 0.808403\n",
      "[200]\ttraining's multi_logloss: 0.767509\tvalid_1's multi_logloss: 0.79811\n",
      "[300]\ttraining's multi_logloss: 0.753683\tvalid_1's multi_logloss: 0.792749\n",
      "[400]\ttraining's multi_logloss: 0.742127\tvalid_1's multi_logloss: 0.788638\n",
      "[500]\ttraining's multi_logloss: 0.728287\tvalid_1's multi_logloss: 0.784145\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.728287\tvalid_1's multi_logloss: 0.784145\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.7841  \u001b[0m | \u001b[0m 0.9331  \u001b[0m | \u001b[0m 384.1   \u001b[0m | \u001b[0m 4.977   \u001b[0m | \u001b[0m 12.42   \u001b[0m | \u001b[0m 2.033   \u001b[0m | \u001b[0m 61.78   \u001b[0m | \u001b[0m 1.544   \u001b[0m | \u001b[0m 5.785   \u001b[0m | \u001b[0m 0.8102  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.794673\tvalid_1's multi_logloss: 0.813172\n",
      "[200]\ttraining's multi_logloss: 0.769809\tvalid_1's multi_logloss: 0.798247\n",
      "[300]\ttraining's multi_logloss: 0.7553\tvalid_1's multi_logloss: 0.792182\n",
      "[400]\ttraining's multi_logloss: 0.743201\tvalid_1's multi_logloss: 0.788144\n",
      "[500]\ttraining's multi_logloss: 0.732646\tvalid_1's multi_logloss: 0.784695\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.732646\tvalid_1's multi_logloss: 0.784695\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.7847  \u001b[0m | \u001b[0m 0.5442  \u001b[0m | \u001b[0m 454.2   \u001b[0m | \u001b[0m 4.655   \u001b[0m | \u001b[0m 37.04   \u001b[0m | \u001b[0m 6.098   \u001b[0m | \u001b[0m 63.63   \u001b[0m | \u001b[0m 0.2421  \u001b[0m | \u001b[0m 4.267   \u001b[0m | \u001b[0m 0.9594  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.794629\tvalid_1's multi_logloss: 0.812912\n",
      "[200]\ttraining's multi_logloss: 0.770393\tvalid_1's multi_logloss: 0.79832\n",
      "[300]\ttraining's multi_logloss: 0.754798\tvalid_1's multi_logloss: 0.791735\n",
      "[400]\ttraining's multi_logloss: 0.742153\tvalid_1's multi_logloss: 0.78768\n",
      "[500]\ttraining's multi_logloss: 0.731052\tvalid_1's multi_logloss: 0.784153\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.731052\tvalid_1's multi_logloss: 0.784153\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.7842  \u001b[0m | \u001b[0m 0.5459  \u001b[0m | \u001b[0m 425.3   \u001b[0m | \u001b[0m 4.91    \u001b[0m | \u001b[0m 55.15   \u001b[0m | \u001b[0m 2.378   \u001b[0m | \u001b[0m 46.55   \u001b[0m | \u001b[0m 1.489   \u001b[0m | \u001b[0m 0.3036  \u001b[0m | \u001b[0m 0.6154  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# BayesianOptimization객체를 수행할 함수와 search할 parameter 범위를 설정하여 생성. \n",
    "lgbBO = BayesianOptimization(lgb_roc_eval,bayesian_params , random_state=0)\n",
    "# 함수 반환값이 최대가 되는 입력값 유추를 위한 iteration 수행. \n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8009663514311595, -0.8003783702891311, -0.7904659330873844, -0.8009694054166153, -0.7918341445927425, -0.8131934502724841, -0.8230763607919699, -0.7985552283502667, -0.7893915424914775, -0.8003801907583233, -0.8099447420724155, -0.8013878184960946, -0.7944982164674612, -0.8007872642884186, -0.7948768094331106, -0.7933085573225015, -0.7989108640691488, -0.7937072145318373, -0.7896682520998842, -0.7851798428519491, -0.7880940364573811, -0.7837359820129789, -0.7993830534547174, -0.7924223367422328, -0.7896253673751455, -0.7849264069370321, -0.7955961712356449, -0.7841447168055898, -0.7846951975429296, -0.7841530973483751]\n",
      "maximum target index: 21\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmax(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7837359820129789\n",
      "{'colsample_bytree': 0.9647911988231949, 'max_bin': 491.60363048973545, 'max_depth': 4.885138936967211, 'min_child_samples': 40.99969541540217, 'min_child_weight': 2.1273123403234457, 'num_leaves': 57.853171850472386, 'reg_alpha': 2.011353943228025, 'reg_lambda': 1.687483832390387, 'subsample': 0.9763826910182591}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
    "max_params = max_dict['params']\n",
    "print(max_dict['target'])\n",
    "print(max_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': round(max_params['colsample_bytree'], 3),\n",
    " 'max_bin': int(max_params['max_bin']),\n",
    " 'max_depth': int(max_params['max_depth']),\n",
    " 'min_child_samples': int(max_params['min_child_samples']),\n",
    " 'min_child_weight': int(max_params['min_child_weight']),\n",
    " 'num_leaves': int(max_params['num_leaves']),\n",
    " 'reg_alpha': round(max_params['reg_alpha'], 3),\n",
    " 'reg_lambda': round(max_params['reg_lambda'], 3),\n",
    " 'subsample': round(max_params['subsample'], 3),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07888235, 0.17946021, 0.74165744],\n",
       "       [0.12853917, 0.17754921, 0.69391162],\n",
       "       [0.10740123, 0.20328282, 0.68931595],\n",
       "       ...,\n",
       "       [0.09862079, 0.13586269, 0.76551652],\n",
       "       [0.07610688, 0.1716816 , 0.75221152],\n",
       "       [0.12765025, 0.19571999, 0.67662977]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_model = LGBMClassifier(**params)\n",
    "lgb_model.fit(X_train, y_train, verbose= 100)\n",
    "pred_lgb = lgb_model.predict_proba(X_test)\n",
    "pred_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.055     , 0.22      , 0.725     ],\n",
       "       [0.49      , 0.21      , 0.3       ],\n",
       "       [0.05      , 0.1       , 0.85      ],\n",
       "       ...,\n",
       "       [0.        , 0.03571429, 0.96428571],\n",
       "       [0.55      , 0.27      , 0.18      ],\n",
       "       [0.09      , 0.344     , 0.566     ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "rf.fit(X_train , y_train)\n",
    "pred_rf = rf.predict_proba(X_test)\n",
    "pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#n_estimators : 생성할 tree의 개수\n",
    "\n",
    "#max_features : 최대 선택할 변수의 수\n",
    "#max_features 값을 크게 하면 random forest의 tree들은 같은 변수를 고려하므로 \n",
    "#tree들이 비슷해지고 가장 두드러진 변수를 이용해 데이터에 잘 맞춰짐\n",
    "\n",
    "#max_features를 낮추면 \n",
    "#random forest tree들은 많이 달라지고 각 tree는 데이터에 맞추기 위해 tree의 깊이가 깊어집니다.\n",
    "\n",
    "#max_depth : 랜덤포레스트 안에 있는 각 의사결정나무의 깊이를 설정. \n",
    "# 트리가 깊어질수록 더 잘게 분류를 시키므로 일반적으론 정확도가 높아진다. 하지만 오버피팅의 위험이 존재\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100, 300, 500]\n",
    "}\n",
    "\n",
    "#Revenue의 T, F의 비율이 8,5 : 1.5로 치우처져있으므로 그 비율에 맞게 sampling하는 StratifiedKFold사용\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)\n",
    "\n",
    "# 랜덤포레스트 객체 생성 \n",
    "rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "\n",
    "# f1 스코어 기준으로 GridSearchCV 수행\n",
    "# refit = True :  best estimator로 자동으로 수정됨\n",
    "# n_jobs = -1 : 모든 cpu의 코어를 사용\n",
    "grid_cv = GridSearchCV(rf , param_grid=params , cv=cv, scoring=\"logloss\", n_jobs=-1, refit = True)\n",
    "\n",
    "# 모델 학습\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 f1: {0:.4f}'.format(grid_cv.best_score_))\n",
    "\n",
    "# 최적의 파라미터로 모델 생성 및 예측\n",
    "model = grid_cv.best_estimator_\n",
    "pred_rf = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print('f1: {0:.4f}'.format(metrics.f1_score(y_test , pred_rf)))\n",
    "print('accuracy: {0:.4f}'.format(metrics.accuracy_score(y_test , pred_rf)))\n",
    "print('precision: {0:.4f}'.format(metrics.precision_score(y_test , pred_rf)))\n",
    "print('recall: {0:.4f}'.format(metrics.recall_score(y_test , pred_rf)))\n",
    "\n",
    "# Confusion Matrix\n",
    "metrics.plot_confusion_matrix(model, X_test, y_test, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (pred_lgb + pred_rf)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.133882</td>\n",
       "      <td>0.399460</td>\n",
       "      <td>1.466657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.618539</td>\n",
       "      <td>0.387549</td>\n",
       "      <td>0.993912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.157401</td>\n",
       "      <td>0.303283</td>\n",
       "      <td>1.539316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.167866</td>\n",
       "      <td>0.198452</td>\n",
       "      <td>1.633681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.172979</td>\n",
       "      <td>0.398236</td>\n",
       "      <td>1.428785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>0.185992</td>\n",
       "      <td>0.574653</td>\n",
       "      <td>1.239355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>0.393995</td>\n",
       "      <td>0.770766</td>\n",
       "      <td>0.835239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>0.098621</td>\n",
       "      <td>0.171577</td>\n",
       "      <td>1.729802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>0.626107</td>\n",
       "      <td>0.441682</td>\n",
       "      <td>0.932212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>0.217650</td>\n",
       "      <td>0.539720</td>\n",
       "      <td>1.242630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         0         1         2\n",
       "0     26457  0.133882  0.399460  1.466657\n",
       "1     26458  0.618539  0.387549  0.993912\n",
       "2     26459  0.157401  0.303283  1.539316\n",
       "3     26460  0.167866  0.198452  1.633681\n",
       "4     26461  0.172979  0.398236  1.428785\n",
       "...     ...       ...       ...       ...\n",
       "9995  36452  0.185992  0.574653  1.239355\n",
       "9996  36453  0.393995  0.770766  0.835239\n",
       "9997  36454  0.098621  0.171577  1.729802\n",
       "9998  36455  0.626107  0.441682  0.932212\n",
       "9999  36456  0.217650  0.539720  1.242630\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission[['0','1','2']] = pd.DataFrame(pred)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
